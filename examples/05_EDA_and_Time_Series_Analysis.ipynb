{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - EDA and Time Series Analysis\n",
    "\n",
    "This notebook demonstrates the usage of the newly developed EDA and Time Series modules in the `ML_Engine` library. We will use a public dataset to showcase the functionalities for exploratory data analysis and time series feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:34.743970Z",
     "iopub.status.busy": "2026-02-11T22:11:34.743970Z",
     "iopub.status.idle": "2026-02-11T22:11:38.389368Z",
     "shell.execute_reply": "2026-02-11T22:11:38.389368Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:04.896476Z",
     "start_time": "2026-02-11T22:13:45.325321Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Import from our new modules\n",
    "from ML_Engine.data import eda as data_eda\n",
    "from ML_Engine.visualization import eda as viz_eda\n",
    "from ML_Engine.data import timeseries as data_ts\n",
    "from ML_Engine.visualization import timeseries as viz_ts\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Ensure outputs directory exists\n",
    "output_dir = 'outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "We will use the 'Daily Female Births' dataset, which is a simple univariate time series."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:38.391057Z",
     "iopub.status.busy": "2026-02-11T22:11:38.391057Z",
     "iopub.status.idle": "2026-02-11T22:11:38.901384Z",
     "shell.execute_reply": "2026-02-11T22:11:38.901384Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:05.216510Z",
     "start_time": "2026-02-11T22:14:04.901859Z"
    }
   },
   "source": [
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-total-female-births.csv'\n",
    "df = pd.read_csv(url, header=0, index_col=0, parse_dates=True).squeeze()\n",
    "\n",
    "# For consistency, let's convert it to a DataFrame\n",
    "df = df.to_frame(name='Births')\n",
    "df.index.name = 'Date'\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's use the new EDA modules to quickly understand our dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:38.904235Z",
     "iopub.status.busy": "2026-02-11T22:11:38.904235Z",
     "iopub.status.idle": "2026-02-11T22:11:38.912065Z",
     "shell.execute_reply": "2026-02-11T22:11:38.911488Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:05.247283Z",
     "start_time": "2026-02-11T22:14:05.228125Z"
    }
   },
   "source": [
    "# Get a statistical summary of the DataFrame\n",
    "summary_df = data_eda.summarize(df)\n",
    "print(\"Dataset Summary:\")\n",
    "print(summary_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:38.912065Z",
     "iopub.status.busy": "2026-02-11T22:11:38.912065Z",
     "iopub.status.idle": "2026-02-11T22:11:38.920038Z",
     "shell.execute_reply": "2026-02-11T22:11:38.920038Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:05.263261Z",
     "start_time": "2026-02-11T22:14:05.254273Z"
    }
   },
   "source": [
    "# Analyze the target variable ('Births')\n",
    "target_analysis = data_eda.analyze_target(df, 'Births')\n",
    "print(\"\\nTarget Variable Analysis:\")\n",
    "print(target_analysis)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:38.923744Z",
     "iopub.status.busy": "2026-02-11T22:11:38.920038Z",
     "iopub.status.idle": "2026-02-11T22:11:39.286957Z",
     "shell.execute_reply": "2026-02-11T22:11:39.286957Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:05.581299Z",
     "start_time": "2026-02-11T22:14:05.273261Z"
    }
   },
   "source": [
    "# Get a visual overview of the dataset\n",
    "fig = viz_eda.plot_dataset_overview(df)\n",
    "fig.savefig(os.path.join(output_dir, '05_dataset_overview.png'))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Basic Time Series Plot"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:39.290276Z",
     "iopub.status.busy": "2026-02-11T22:11:39.290276Z",
     "iopub.status.idle": "2026-02-11T22:11:39.598139Z",
     "shell.execute_reply": "2026-02-11T22:11:39.598139Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:05.942958Z",
     "start_time": "2026-02-11T22:14:05.590311Z"
    }
   },
   "source": [
    "# Plot the time series data\n",
    "fig = viz_ts.plot_timeseries(df.reset_index(), date_col='Date', value_col='Births')\n",
    "fig.savefig(os.path.join(output_dir, '05_timeseries_plot.png'))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Stationarity Check"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:39.598139Z",
     "iopub.status.busy": "2026-02-11T22:11:39.598139Z",
     "iopub.status.idle": "2026-02-11T22:11:39.682856Z",
     "shell.execute_reply": "2026-02-11T22:11:39.682856Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:05.980167Z",
     "start_time": "2026-02-11T22:14:05.948594Z"
    }
   },
   "source": [
    "# Check for stationarity using the ADF test\n",
    "p_value, is_stationary, interpretation = data_ts.check_stationarity(df['Births'])\n",
    "print(f\"Is the series stationary? {is_stationary} (p-value: {p_value:.4f})\")\n",
    "print(\"ADF Test Results:\", interpretation)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. ACF and PACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:39.687616Z",
     "iopub.status.busy": "2026-02-11T22:11:39.682856Z",
     "iopub.status.idle": "2026-02-11T22:11:40.509901Z",
     "shell.execute_reply": "2026-02-11T22:11:40.509901Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:06.608949Z",
     "start_time": "2026-02-11T22:14:05.984421Z"
    }
   },
   "source": [
    "# Plot ACF and PACF to identify potential model parameters (p, d, q)\n",
    "fig = viz_ts.plot_acf_pacf(df['Births'], lags=40)\n",
    "fig.savefig(os.path.join(output_dir, '05_acf_pacf.png'))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Seasonality Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:40.509901Z",
     "iopub.status.busy": "2026-02-11T22:11:40.509901Z",
     "iopub.status.idle": "2026-02-11T22:11:42.157385Z",
     "shell.execute_reply": "2026-02-11T22:11:42.157385Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:08.609836Z",
     "start_time": "2026-02-11T22:14:06.614352Z"
    }
   },
   "source": [
    "# Decompose the time series to observe trend, seasonality, and residuals\n",
    "# Assuming a weekly seasonality (period=7)\n",
    "fig = viz_ts.plot_seasonality_decomposition(df['Births'], period=7)\n",
    "fig.savefig(os.path.join(output_dir, '05_decomposition.png'))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:42.157385Z",
     "iopub.status.busy": "2026-02-11T22:11:42.157385Z",
     "iopub.status.idle": "2026-02-11T22:11:42.182201Z",
     "shell.execute_reply": "2026-02-11T22:11:42.182201Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:08.654938Z",
     "start_time": "2026-02-11T22:14:08.620642Z"
    }
   },
   "source": [
    "# Create date-based features\n",
    "df_featured = data_ts.extract_date_features(df.reset_index(), 'Date')\n",
    "\n",
    "# Create lag features\n",
    "df_featured = data_ts.create_lag_features(df_featured, 'Births', lags=[1, 7, 30])\n",
    "\n",
    "# Create rolling window features\n",
    "df_featured = data_ts.create_rolling_features(df_featured, 'Births', windows=[7, 30], agg=['mean', 'std'])\n",
    "\n",
    "df_featured.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time Series Splitting\n",
    "\n",
    "Finally, let's demonstrate how to split the data for time series modeling."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:42.182201Z",
     "iopub.status.busy": "2026-02-11T22:11:42.182201Z",
     "iopub.status.idle": "2026-02-11T22:11:42.192473Z",
     "shell.execute_reply": "2026-02-11T22:11:42.192473Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:08.671002Z",
     "start_time": "2026-02-11T22:14:08.661420Z"
    }
   },
   "source": [
    "# Drop rows with NaNs created by feature engineering\n",
    "df_featured_clean = df_featured.dropna()\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = data_ts.split_timeseries(df_featured_clean, date_col='Date', test_size=0.2)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(\"\\nTraining data starts:\", X_train['Date'].min())\n",
    "print(\"Training data ends:\", X_train['Date'].max())\n",
    "print(\"Test data starts:\", X_test['Date'].min())\n",
    "print(\"Test data ends:\", X_test['Date'].max())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Financial Time Series Analysis\n",
    "\n",
    "In this section, we demonstrate more sophisticated time series analysis using financial data.\n",
    "We'll use Apple Inc. (AAPL) stock data to showcase advanced EDA and time series feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:42.195430Z",
     "iopub.status.busy": "2026-02-11T22:11:42.195430Z",
     "iopub.status.idle": "2026-02-11T22:11:42.914569Z",
     "shell.execute_reply": "2026-02-11T22:11:42.914569Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:08.944656Z",
     "start_time": "2026-02-11T22:14:08.677477Z"
    }
   },
   "source": [
    "# Install yfinance if not already installed\n",
    "try:\n",
    "    import yfinance\n",
    "except ImportError:\n",
    "    !pip install yfinance -q\n",
    "    import yfinance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:42.914569Z",
     "iopub.status.busy": "2026-02-11T22:11:42.914569Z",
     "iopub.status.idle": "2026-02-11T22:11:43.982140Z",
     "shell.execute_reply": "2026-02-11T22:11:43.982140Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:10.104316Z",
     "start_time": "2026-02-11T22:14:08.949585Z"
    }
   },
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Download AAPL stock data for the last 2 years\n",
    "ticker = 'AAPL'\n",
    "df_fin = yf.download(ticker, period='2y', interval='1d', progress=False)\n",
    "df_fin.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:43.982140Z",
     "iopub.status.busy": "2026-02-11T22:11:43.982140Z",
     "iopub.status.idle": "2026-02-11T22:11:44.002346Z",
     "shell.execute_reply": "2026-02-11T22:11:44.002346Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:10.145158Z",
     "start_time": "2026-02-11T22:14:10.110519Z"
    }
   },
   "source": [
    "# Basic statistics\n",
    "print(f\"Data shape: {df_fin.shape}\")\n",
    "print(\"\\nColumn dtypes:\")\n",
    "print(df_fin.dtypes)\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df_fin.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df_fin.isnull().sum())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:44.002346Z",
     "iopub.status.busy": "2026-02-11T22:11:44.002346Z",
     "iopub.status.idle": "2026-02-11T22:11:44.016971Z",
     "shell.execute_reply": "2026-02-11T22:11:44.016971Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:10.177154Z",
     "start_time": "2026-02-11T22:14:10.151153Z"
    }
   },
   "source": [
    "# Calculate daily returns and volatility\n",
    "df_fin['Returns'] = df_fin['Close'].pct_change()\n",
    "df_fin['Log_Returns'] = np.log(df_fin['Close'] / df_fin['Close'].shift(1))\n",
    "df_fin['Volatility'] = df_fin['Returns'].rolling(window=30).std() * np.sqrt(252)  # annualized\n",
    "\n",
    "# Drop NaN rows created by shifts\n",
    "df_fin_clean = df_fin.dropna()\n",
    "\n",
    "print(\"First few rows with returns and volatility:\")\n",
    "print(df_fin_clean[['Close', 'Returns', 'Log_Returns', 'Volatility']].head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:44.019525Z",
     "iopub.status.busy": "2026-02-11T22:11:44.019525Z",
     "iopub.status.idle": "2026-02-11T22:11:44.732304Z",
     "shell.execute_reply": "2026-02-11T22:11:44.732304Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:11.054156Z",
     "start_time": "2026-02-11T22:14:10.183154Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot closing price and returns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Closing price\n",
    "axes[0, 0].plot(df_fin_clean.index, df_fin_clean['Close'], color='blue', linewidth=1)\n",
    "axes[0, 0].set_title('AAPL Closing Price')\n",
    "axes[0, 0].set_ylabel('Price (USD)')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Daily returns\n",
    "axes[0, 1].plot(df_fin_clean.index, df_fin_clean['Returns'], color='green', linewidth=1)\n",
    "axes[0, 1].set_title('Daily Returns')\n",
    "axes[0, 1].set_ylabel('Returns')\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Volume (line plot)axes[1, 0].plot(df_fin_clean.index, df_fin_clean['Volume'], color='gray', linewidth=1)axes[1, 0].set_title('Trading Volume')axes[1, 0].set_ylabel('Volume')axes[1, 0].grid(True)\n",
    "# Rolling volatility\n",
    "axes[1, 1].plot(df_fin_clean.index, df_fin_clean['Volatility'], color='red', linewidth=1)\n",
    "axes[1, 1].set_title('30-Day Rolling Volatility (Annualized)')\n",
    "axes[1, 1].set_ylabel('Volatility')\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:44.732304Z",
     "iopub.status.busy": "2026-02-11T22:11:44.732304Z",
     "iopub.status.idle": "2026-02-11T22:11:44.746569Z",
     "shell.execute_reply": "2026-02-11T22:11:44.746569Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:11.076530Z",
     "start_time": "2026-02-11T22:14:11.060319Z"
    }
   },
   "source": [
    "# Use our new EDA modules\n",
    "from ML_Engine.data.eda import summarize, analyze_target\n",
    "from ML_Engine.visualization.eda import plot_dataset_overview, plot_correlations\n",
    "\n",
    "# Summarize the financial DataFrame\n",
    "summary = summarize(df_fin_clean)\n",
    "print(\"Financial Data Summary:\")\n",
    "print(summary)\n",
    "\n",
    "# Analyze a target variable (e.g., Returns)\n",
    "target_analysis = analyze_target(df_fin_clean, 'Returns')\n",
    "print(\"\\nReturns Analysis:\")\n",
    "print(target_analysis)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:44.746569Z",
     "iopub.status.busy": "2026-02-11T22:11:44.746569Z",
     "iopub.status.idle": "2026-02-11T22:11:45.053317Z",
     "shell.execute_reply": "2026-02-11T22:11:45.053317Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:11.436049Z",
     "start_time": "2026-02-11T22:14:11.085198Z"
    }
   },
   "source": [
    "# Plot correlations between financial features\n",
    "fig = plot_correlations(df_fin_clean[['Open', 'High', 'Low', 'Close', 'Volume', 'Returns', 'Volatility']])\n",
    "fig.suptitle('Correlation Matrix - Financial Features', fontsize=16)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:45.053317Z",
     "iopub.status.busy": "2026-02-11T22:11:45.053317Z",
     "iopub.status.idle": "2026-02-11T22:11:45.070835Z",
     "shell.execute_reply": "2026-02-11T22:11:45.070835Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:11.466483Z",
     "start_time": "2026-02-11T22:14:11.447875Z"
    }
   },
   "source": [
    "# Use our time series modules\n",
    "from ML_Engine.data.timeseries import extract_date_features, create_lag_features, create_rolling_features\n",
    "from ML_Engine.visualization.timeseries import plot_acf_pacf, plot_seasonality_decomposition\n",
    "\n",
    "# Reset index to have Date as a column\n",
    "df_fin_reset = df_fin_clean.reset_index()\n",
    "\n",
    "# Extract date features\n",
    "df_with_date_features = extract_date_features(df_fin_reset, 'Date')\n",
    "print(\"Date features added. New columns:\")\n",
    "print([col for col in df_with_date_features.columns if 'Date' in col])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:45.074363Z",
     "iopub.status.busy": "2026-02-11T22:11:45.074363Z",
     "iopub.status.idle": "2026-02-11T22:11:45.098876Z",
     "shell.execute_reply": "2026-02-11T22:11:45.098876Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:11.518377Z",
     "start_time": "2026-02-11T22:14:11.479018Z"
    }
   },
   "source": [
    "# Create lag features for Returns\n",
    "df_with_lags = create_lag_features(df_with_date_features, 'Returns', lags=[1, 2, 3, 5, 10])\n",
    "\n",
    "# Create rolling features for Returns\n",
    "df_with_rolling = create_rolling_features(df_with_lags, 'Returns', windows=[5, 10, 20], agg=['mean', 'std', 'min', 'max'])\n",
    "\n",
    "print(f\"DataFrame shape after feature engineering: {df_with_rolling.shape}\")\n",
    "print(\"\\nSample of engineered features:\")\n",
    "print(df_with_rolling[['Returns', 'Returns_lag_1', 'Returns_rolling_5_mean', 'Returns_rolling_10_std']].head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:45.102930Z",
     "iopub.status.busy": "2026-02-11T22:11:45.098876Z",
     "iopub.status.idle": "2026-02-11T22:11:45.118202Z",
     "shell.execute_reply": "2026-02-11T22:11:45.117373Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:11.553312Z",
     "start_time": "2026-02-11T22:14:11.525626Z"
    }
   },
   "source": [
    "# Check stationarity of returns series\n",
    "from ML_Engine.data.timeseries import check_stationarity\n",
    "\n",
    "p_value, is_stationary, interpretation = check_stationarity(df_fin_clean['Returns'])\n",
    "print(f\"Is the returns series stationary? {is_stationary} (p-value: {p_value:.6f})\")\n",
    "print(\"\\nADF Test Results:\")\n",
    "for key, value in interpretation.items():\n",
    "    print(f\"  {key}: {value}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:45.119800Z",
     "iopub.status.busy": "2026-02-11T22:11:45.119800Z",
     "iopub.status.idle": "2026-02-11T22:11:45.446103Z",
     "shell.execute_reply": "2026-02-11T22:11:45.445752Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:11.961298Z",
     "start_time": "2026-02-11T22:14:11.584812Z"
    }
   },
   "source": [
    "# Plot ACF and PACF for returns\n",
    "fig = plot_acf_pacf(df_fin_clean['Returns'], lags=40)\n",
    "fig.suptitle('ACF and PACF - AAPL Daily Returns', fontsize=16)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:45.447360Z",
     "iopub.status.busy": "2026-02-11T22:11:45.447360Z",
     "iopub.status.idle": "2026-02-11T22:11:46.705077Z",
     "shell.execute_reply": "2026-02-11T22:11:46.705077Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:13.455626Z",
     "start_time": "2026-02-11T22:14:11.968723Z"
    }
   },
   "source": [
    "# Try seasonality decomposition (assuming weekly seasonality for trading days)\n",
    "# Note: Financial data typically has 5 trading days per week\n",
    "try:\n",
    "    fig = plot_seasonality_decomposition(df_fin_clean['Returns'].dropna(), period=5)\n",
    "    fig.suptitle('Seasonality Decomposition - AAPL Daily Returns (5-day period)', fontsize=16)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Seasonality decomposition failed: {e}\")\n",
    "    print(\"This is expected if there's no clear seasonality in the returns series.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T22:11:46.705077Z",
     "iopub.status.busy": "2026-02-11T22:11:46.705077Z",
     "iopub.status.idle": "2026-02-11T22:11:46.718655Z",
     "shell.execute_reply": "2026-02-11T22:11:46.718655Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-11T22:14:13.492251Z",
     "start_time": "2026-02-11T22:14:13.469646Z"
    }
   },
   "source": [
    "\n",
    "# Demonstrate time series split\n",
    "from ML_Engine.data.timeseries import split_timeseries\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare a feature matrix (using engineered features)\n",
    "# Flatten MultiIndex columns to strings\n",
    "if isinstance(df_with_rolling.columns, pd.MultiIndex):\n",
    "    df_with_rolling.columns = ['_'.join(col).strip('_') for col in df_with_rolling.columns]\n",
    "feature_cols = [col for col in df_with_rolling.columns if col not in ['Date', 'Returns'] and not col.startswith('Date_')]\n",
    "feature_cols = feature_cols[:10]  # Limit to first 10 features for demonstration\n",
    "target_col = 'Returns'\n",
    "\n",
    "df_for_split = df_with_rolling[['Date'] + feature_cols + [target_col]].dropna()\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_timeseries(df_for_split, date_col='Date', test_size=0.2)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Training period: {X_train['Date'].min()} to {X_train['Date'].max()}\")\n",
    "print(f\"Test period: {X_test['Date'].min()} to {X_test['Date'].max()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This advanced financial time series analysis demonstrates:\n",
    "\n",
    "1. **Financial Data Acquisition**: Using `yfinance` to download real stock data\n",
    "2. **Advanced EDA**: Returns calculation, volatility measurement, and correlation analysis\n",
    "3. **ML_Engine Integration**: Using the new EDA and time series modules for automated analysis\n",
    "4. **Feature Engineering**: Date features, lag features, and rolling window statistics\n",
    "5. **Time Series Diagnostics**: Stationarity testing, ACF/PACF analysis, and seasonality decomposition\n",
    "6. **Temporal Splitting**: Proper time-aware train/test split for forecasting tasks\n",
    "\n",
    "The engineered features can now be used with the existing `ML_Engine.models` module for time series forecasting, demonstrating the full integration of the new time series capabilities with the existing ML pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}